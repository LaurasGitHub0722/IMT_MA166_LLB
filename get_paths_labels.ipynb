{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch1.2.0_get_paths_labels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TnHVCfC49Dr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03608a73-873e-4ab7-91b8-a938e85cd8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code fÃ¼r torch v 1.2.0\n",
        "# get_paths_labels \n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/MA_LL/Datensatz_1143/'\n",
        "img_dir = os.path.join(root_dir, 'data_resize')\n",
        "phase_dir = os.path.join(root_dir, 'Phase_annotations_1143')\n",
        "\n",
        "print(root_dir)\n",
        "print(img_dir)\n",
        "print(phase_dir)\n",
        "\n",
        "\n",
        "def get_dirs(root_dir):\n",
        "    file_paths = []\n",
        "    file_names = []\n",
        "    for lists in os.listdir(root_dir):\n",
        "        path = os.path.join(root_dir, lists)\n",
        "        if os.path.isdir(path):\n",
        "            file_paths.append(path)\n",
        "            file_names.append(os.path.basename(path))\n",
        "    file_names.sort()\n",
        "    file_paths.sort()\n",
        "    return file_names, file_paths\n",
        "\n",
        "def get_files(root_dir):\n",
        "    file_paths = []\n",
        "    file_names = []\n",
        "    for lists in os.listdir(root_dir):\n",
        "        path = os.path.join(root_dir, lists)\n",
        "        if not os.path.isdir(path):\n",
        "            file_paths.append(path)\n",
        "            file_names.append(os.path.basename(path))\n",
        "    file_names.sort()\n",
        "    file_paths.sort()\n",
        "    return file_names, file_paths\n",
        "\n",
        "\n",
        "img_dir_names, img_dir_paths = get_dirs(img_dir)\n",
        "phase_file_names, phase_file_paths = get_files(phase_dir)\n",
        "\n",
        "phase_dict = {}\n",
        "phase_dict_key = ['None', 'Greifen', 'Phase']\n",
        "for i in range(len(phase_dict_key)):\n",
        "    phase_dict[phase_dict_key[i]] = i\n",
        "print(phase_dict)\n",
        "\n",
        "\n",
        "all_info_all = []\n",
        "\n",
        "for j in range(len(phase_file_names)):\n",
        "\n",
        "    phase_file = open(phase_file_paths[j])\n",
        "    phase_count = 0\n",
        "    file_count = 0\n",
        "    frame_num = len(os.listdir(img_dir_paths[j]))\n",
        "    info_all = []\n",
        "    for phase_line in phase_file:\n",
        "        phase_count += 1\n",
        "        if phase_count > 1:\n",
        "            if file_count <= frame_num:\n",
        "                file_count += 1\n",
        "                phase_split = phase_line.split()\n",
        "                info_each = []\n",
        "                img_file_each_path = os.path.join(img_dir_paths[j], img_dir_names[j] + '-' + str(file_count) + '.jpg')\n",
        "                info_each.append(img_file_each_path)\n",
        "                info_each.append(phase_dict[phase_split[1]])\n",
        "                info_all.append(info_each)          \n",
        "\n",
        "    # print(len(info_all))\n",
        "    all_info_all.append(info_all)\n",
        "\n",
        "#for k in range(10):\n",
        "#print(all_info_all[0][k])\n",
        "with open('Greifen.pkl', 'wb') as f:\n",
        "    pickle.dump(all_info_all, f)\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('Greifen.pkl', 'rb') as f:\n",
        "    all_info = pickle.load(f)\n",
        "\n",
        "train_file_paths = []\n",
        "test_file_paths = []\n",
        "val_file_paths = []\n",
        "val_labels = []\n",
        "train_labels = []\n",
        "test_labels = []\n",
        "\n",
        "train_num_each = []\n",
        "val_num_each = []\n",
        "test_num_each = []\n",
        "\n",
        "for i in range(914):\n",
        "    train_num_each.append(len(all_info[i]))\n",
        "    for j in range(len(all_info[i])):\n",
        "        train_file_paths.append(all_info[i][j][0])\n",
        "        train_labels.append(all_info[i][j][1:])\n",
        "\n",
        "print(len(train_file_paths))\n",
        "print(len(train_labels))\n",
        "\n",
        "for i in range(914, 1029):\n",
        "    val_num_each.append(len(all_info[i]))\n",
        "    for j in range(len(all_info[i])):\n",
        "        val_file_paths.append(all_info[i][j][0])\n",
        "        val_labels.append(all_info[i][j][1:])\n",
        "\n",
        "print(len(val_file_paths))\n",
        "print(len(val_labels))\n",
        "\n",
        "for i in range(1029, 1143):\n",
        "    test_num_each.append(len(all_info[i]))\n",
        "    for j in range(len(all_info[i])):\n",
        "        test_file_paths.append(all_info[i][j][0])\n",
        "        test_labels.append(all_info[i][j][1:])\n",
        "\n",
        "print(len(test_file_paths))\n",
        "print(len(test_labels))\n",
        "\n",
        "# for i in range(10):\n",
        "#     print(train_file_paths[i], train_labels[i])\n",
        "#     print(test_file_paths[i], test_labels[i])\n",
        "\n",
        "train_val_test_paths_labels = []\n",
        "train_val_test_paths_labels.append(train_file_paths)\n",
        "train_val_test_paths_labels.append(val_file_paths)\n",
        "train_val_test_paths_labels.append(test_file_paths)\n",
        "\n",
        "train_val_test_paths_labels.append(train_labels)\n",
        "train_val_test_paths_labels.append(val_labels)\n",
        "train_val_test_paths_labels.append(test_labels)\n",
        "\n",
        "train_val_test_paths_labels.append(train_num_each)\n",
        "train_val_test_paths_labels.append(val_num_each)\n",
        "train_val_test_paths_labels.append(test_num_each)\n",
        "\n",
        "with open('/content/drive/MyDrive/MA_LL/Datensatz_1143/train_val_test_paths_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(train_val_test_paths_labels, f)\n",
        "\n",
        "\n",
        "print('Done')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg8tbQe7Chde",
        "outputId": "4140f597-9b13-48b3-f7ca-379654d36ab6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MA_LL/Datensatz_1143/\n",
            "/content/drive/MyDrive/MA_LL/Datensatz_1143/data_resize\n",
            "/content/drive/MyDrive/MA_LL/Datensatz_1143/Phase_annotations_1143\n",
            "{'None': 0, 'Greifen': 1, 'Phase': 2}\n",
            "104390\n",
            "104390\n",
            "12451\n",
            "12451\n",
            "11369\n",
            "11369\n",
            "Done\n",
            "\n"
          ]
        }
      ]
    }
  ]
}