{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc9KOSJZ3SBc",
        "outputId": "dd319732-2af0-4f0f-f21d-333df5c86fb8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from random import choice\n",
        "import shutil\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Ordner f√ºr das Video anlegen\n",
        "VideoPath ='/content/drive/MyDrive/Greifen/Test/video'\n",
        "print(os.listdir(VideoPath))\n",
        "for video in os.listdir(VideoPath):\n",
        "      name, endung = video.split('.')\n",
        "      if not os.path.isdir(filePath + name):\n",
        "        os.makedirs(\"/content/drive/MyDrive/Greifen/Test/\" + name ) \n",
        "\n",
        "        print('Ordner erstellt')\n",
        "        print(name)\n",
        "      else:\n",
        "        print('Ordner besteht')\n",
        "\n",
        "\n",
        "vidcap = cv2.VideoCapture('/content/drive/MyDrive/Greifen/Test/video/Greifen_2_130767.mp4')\n",
        "success,image = vidcap.read()\n",
        "count = 1\n",
        "while success:    \n",
        "      cv2.imwrite(\"/content/drive/MyDrive/Greifen/Test/video/Greifen_2_130767/Greifen_2_130767-%d.jpg\" % count, image)\n",
        "      success,image = vidcap.read()\n",
        "      print('Read a new frame: ', success)\n",
        "      count += 1\n",
        "\n",
        "\n",
        "#AnzahlFrames = 0\n",
        "#for path in pathlib.Path(\"/content/drive/MyDrive/MA_LL/Test_Video_Greifen_1_310426/Greifen_1_310426\").iterdir():\n",
        "#    if path.is_file():\n",
        "#        AnzahlFrames += 1\n",
        "#count = 1\n",
        "#while count < (AnzahlFrames + 1):\n",
        "#    image = Image.open('/content/drive/MyDrive/MA_LL/Test_Video_Greifen_1_310426/Greifen_1_310426/Greifen_1_310426-%d.jpg' % count)\n",
        "#    new_image = image.resize((250, 250))\n",
        "#    new_image.save('/content/drive/MyDrive/MA_LL/Test_Video_Greifen_1_310426/data_resized/Greifen_1_310426-%d.jpg' % count)\n",
        "#    print(count)\n",
        "#    print(new_image.size)\n",
        "#    count += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li3irRrocjpG",
        "outputId": "7428041f-5c31-4e2e-d1f6-63ece102e0e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Greifen_2_130767.mp4']\n",
            "Ordner erstellt\n",
            "Greifen_2_130767\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  True\n",
            "Read a new frame:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NinIkYoBN42V",
        "outputId": "2b9c4caf-e667-4292-9e07-0c1059546f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame:  1\n",
            "None\n",
            "Frame:  2\n",
            "Greifen\n",
            "Frame:  3\n",
            "Greifen\n",
            "Frame:  4\n",
            "Greifen\n",
            "Frame:  5\n",
            "Greifen\n",
            "Frame:  6\n",
            "None\n",
            "Frame:  7\n",
            "Greifen\n",
            "Frame:  8\n",
            "Greifen\n",
            "Frame:  9\n",
            "Greifen\n",
            "Frame: 10\n",
            "Greifen\n",
            "Frame: 11\n",
            "Greifen\n",
            "Frame: 12\n",
            "Greifen\n",
            "Frame: 13\n",
            "Greifen\n",
            "Frame: 14\n",
            "Greifen\n",
            "Frame: 15\n",
            "Greifen\n",
            "Frame: 16\n",
            "Greifen\n",
            "Frame: 17\n",
            "Greifen\n",
            "Frame: 18\n",
            "Greifen\n",
            "Frame: 19\n",
            "Greifen\n",
            "Frame: 20\n",
            "Greifen\n",
            "Frame: 21\n",
            "Greifen\n",
            "Frame: 22\n",
            "Greifen\n",
            "Frame: 23\n",
            "Greifen\n",
            "Frame: 24\n",
            "Greifen\n",
            "Frame: 25\n",
            "Greifen\n",
            "Frame: 26\n",
            "Greifen\n",
            "Frame: 27\n",
            "Greifen\n",
            "Frame: 28\n",
            "Greifen\n",
            "Frame: 29\n",
            "Greifen\n",
            "Frame: 30\n",
            "Greifen\n",
            "Frame: 31\n",
            "Greifen\n",
            "Frame: 32\n",
            "Greifen\n",
            "Frame: 33\n",
            "Greifen\n",
            "Frame: 34\n",
            "Greifen\n",
            "Frame: 35\n",
            "Greifen\n",
            "Frame: 36\n",
            "Greifen\n",
            "Frame: 37\n",
            "Greifen\n",
            "Frame: 38\n",
            "Greifen\n",
            "Frame: 39\n",
            "Greifen\n",
            "Frame: 40\n",
            "Greifen\n",
            "Frame: 41\n",
            "Greifen\n",
            "Frame: 42\n",
            "Greifen\n",
            "Frame: 43\n",
            "Greifen\n",
            "Frame: 44\n",
            "Greifen\n",
            "Frame: 45\n",
            "Greifen\n",
            "Frame: 46\n",
            "Greifen\n",
            "Frame: 47\n",
            "Greifen\n",
            "Frame: 48\n",
            "Greifen\n",
            "Frame: 49\n",
            "None\n",
            "Frame: 50\n",
            "None\n",
            "Frame: 51\n",
            "None\n",
            "Frame: 52\n",
            "Greifen\n",
            "Frame: 53\n",
            "None\n",
            "Frame: 54\n",
            "Greifen\n",
            "Frame: 55\n",
            "Greifen\n",
            "Frame: 56\n",
            "Greifen\n",
            "Frame: 57\n",
            "Greifen\n",
            "Frame: 58\n",
            "Greifen\n",
            "Frame: 59\n",
            "Greifen\n",
            "Frame: 60\n",
            "Greifen\n",
            "Frame: 61\n",
            "Greifen\n",
            "Frame: 62\n",
            "Greifen\n",
            "Frame: 63\n",
            "Greifen\n",
            "Frame: 64\n",
            "Greifen\n",
            "Frame: 65\n",
            "Greifen\n",
            "Frame: 66\n",
            "Greifen\n",
            "Frame: 67\n",
            "Greifen\n",
            "Frame: 68\n",
            "Greifen\n",
            "Frame: 69\n",
            "Greifen\n",
            "Frame: 70\n",
            "Greifen\n",
            "Frame: 71\n",
            "Greifen\n",
            "Frame: 72\n",
            "Greifen\n",
            "Frame: 73\n",
            "Greifen\n",
            "Frame: 74\n",
            "Greifen\n",
            "Frame: 75\n",
            "Greifen\n",
            "Frame: 76\n",
            "Greifen\n",
            "Frame: 77\n",
            "Greifen\n",
            "Frame: 78\n",
            "Greifen\n",
            "Frame: 79\n",
            "Greifen\n",
            "Frame: 80\n",
            "Greifen\n",
            "Frame: 81\n",
            "Greifen\n",
            "Frame: 82\n",
            "Greifen\n",
            "Frame: 83\n",
            "None\n",
            "Frame: 84\n",
            "Greifen\n",
            "Frame: 85\n",
            "Greifen\n",
            "Frame: 86\n",
            "Greifen\n",
            "Frame: 87\n",
            "Greifen\n",
            "Frame: 88\n",
            "Greifen\n",
            "Frame: 89\n",
            "Greifen\n",
            "Frame: 90\n",
            "None\n",
            "L√§nge Video: 3.0000 sec\n",
            "Start Greifen: 0.7000 sec, Ende Greifen: 2.8000 sec\n"
          ]
        }
      ],
      "source": [
        "# Erstelle Text Datei mit Vorhersage(Phase, None) pro Frame\n",
        "# Erstelle Test Datei mit zeitlicher Prediction f√ºr Phase Greifen \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image, ImageFile\n",
        "import os\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.init as init\n",
        "from torch.nn import DataParallel\n",
        "import numpy as np\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Modell laden\n",
        "class resnet_lstm(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resnet_lstm, self).__init__()\n",
        "        resnet = models.resnet50(pretrained=True)\n",
        "        self.share = torch.nn.Sequential()\n",
        "        self.share.add_module(\"conv1\", resnet.conv1)\n",
        "        self.share.add_module(\"bn1\", resnet.bn1)\n",
        "        self.share.add_module(\"relu\", resnet.relu)\n",
        "        self.share.add_module(\"maxpool\", resnet.maxpool)\n",
        "        self.share.add_module(\"layer1\", resnet.layer1)\n",
        "        self.share.add_module(\"layer2\", resnet.layer2)\n",
        "        self.share.add_module(\"layer3\", resnet.layer3)\n",
        "        self.share.add_module(\"layer4\", resnet.layer4)\n",
        "        self.share.add_module(\"avgpool\", resnet.avgpool)\n",
        "        self.lstm = nn.LSTM(2048, 512, batch_first=True)\n",
        "        self.lstm = nn.LSTM(2048, 512, batch_first=True)\n",
        "        self.fcDropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(512, 7)\n",
        "\n",
        "        init.xavier_normal_(self.lstm.all_weights[0][0])\n",
        "        init.xavier_normal_(self.lstm.all_weights[0][1])\n",
        "        init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3, 224, 224)\n",
        "        x = self.share.forward(x)\n",
        "        x = x.view(-1, 2048)\n",
        "       # x = x.view(-1, 10, 2048)\n",
        "        self.lstm.flatten_parameters()\n",
        "        y, _ = self.lstm(x)\n",
        "        y = y.contiguous().view(-1, 512)\n",
        "        # y = self.fcDropout(y)\n",
        "        y = self.fc(y)\n",
        "        return y\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "model = resnet_lstm()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Greifen/Greifen2_run01/lstm_epoch_14_length_10_opt_1_mulopt_1_flip_1_crop_1_batch_50_train_9762_val_9468.pth'))\n",
        "model = DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "phase_key = ['None', 'Greifen']\n",
        "\n",
        "# Input transformieren\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.Resize((250, 250)),                                  \n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.3456, 0.2281, 0.2233], [0.2528, 0.2135, 0.2104]), \n",
        "    ]) \n",
        "\n",
        "# Prediction\n",
        "count = 1\n",
        "i = 1\n",
        "k = 1\n",
        "for element in os.listdir('/content/drive/MyDrive/Greifen/Test/Greifen_2_130767'):           \n",
        "    img = Image.open(\"/content/drive/MyDrive/Greifen/Test/Greifen_2_130767/Greifen_2_130767-%d.jpg\" %count)\n",
        "    img = img_transforms(img).to(device)  \n",
        "    img = torch.unsqueeze(img, 0)\n",
        "\n",
        "    model.eval()\n",
        "    prediction = F.softmax(model(img), dim=1)\n",
        "    prediction = prediction.argmax()\n",
        "    print('Frame: {:2d}'.format(count))\n",
        "    print(phase_key[prediction])\n",
        "\n",
        "    if phase_key[prediction] == 'Greifen':\n",
        "        i += 1\n",
        "    \n",
        "    if i > 20 and phase_key[prediction] == 'Greifen':\n",
        "        with open(\"/content/drive/MyDrive/Greifen/Test/Bericht_Greifen_2_130767.txt\") as text_file:\n",
        "            with open(\"/content/drive/MyDrive/Greifen/Test/Bericht_Greifen_2_130767.txt\", \"a\") as text_file: #'a' Text wird bestehender Datei immer wieder angeh√§ngt \n",
        "                  #text = 'Frame ' + str(count) + ': ' + phase_key[prediction] + '\\n'\n",
        "                  #text = phase_key[prediction] + '\\n'\n",
        "                  text = 'Greifen\\n'\n",
        "                  text_file.write(\"%s\" % text)\n",
        "    else: \n",
        "        with open(\"/content/drive/MyDrive/Greifen/Test/Bericht_Greifen_2_130767.txt\", \"a\") as text_file: #'a' Text wird bestehender Datei immer wieder angeh√§ngt \n",
        "            #text = 'Frame ' + str(count) + ': ' + 'None\\n'\n",
        "            text = 'None\\n'\n",
        "            text_file.write(\"%s\" % text)\n",
        "    count += 1  \n",
        "\n",
        "# Text Datei f√ºr zeitliche Vorhersage \n",
        "total_lines = 0\n",
        "greifen_count = 0\n",
        "none_count = 0\n",
        "with open('/content/drive/MyDrive/Greifen/Test/Bericht_Greifen_2_130767.txt', 'r') as file:\n",
        "    begin = next((i for i, line in enumerate(file, 1) if line.rstrip() == 'Greifen'),0)\n",
        "    for line in file: \n",
        "        if 'Greifen' in line:\n",
        "            greifen_count += 1\n",
        "\n",
        "with open('/content/drive/MyDrive/Greifen/Test/Bericht_Greifen_2_130767.txt') as file:\n",
        "    total_lines = sum(1 for line in file)\n",
        "#print(begin)\n",
        "#print(greifen_count)\n",
        "#print(total_lines)\n",
        "\n",
        "start = round(begin/30,1)\n",
        "ende = round((begin+greifen_count)/30,1)\n",
        "l√§nge = round((total_lines)/30,1)\n",
        "\n",
        "print('L√§nge Video: {:.4f} sec'.format(l√§nge))\n",
        "print('Start Greifen: {:.4f} sec, Ende Greifen: {:.4f} sec'.format(start, ende))\n",
        "       \n",
        "with open('/content/drive/MyDrive/Greifen/Test/pred_time_Greifen_2_130767.txt', 'w') as text_file:\n",
        "    text = 'L√§nge Video: ' + str(l√§nge) + '\\n' + 'Start Greifen: ' + str(start) + ' sec\\n' + 'Ende Greifen: ' + str(ende) + ' sec'\n",
        "    text_file.write(\"%s\" % text)\n",
        "\n",
        "\n"
      ]
    }
  ]
}